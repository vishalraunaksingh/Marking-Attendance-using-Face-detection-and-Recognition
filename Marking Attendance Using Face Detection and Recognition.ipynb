{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From a File Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found 5 face(s) in this image.\n",
      "A face is detected at pixel location Top: 311, Left: 698, Bottom: 440, Right: 569\n",
      "A face is detected at pixel location Top: 297, Left: 999, Bottom: 426, Right: 870\n",
      "A face is detected at pixel location Top: 288, Left: 528, Bottom: 442, Right: 373\n",
      "A face is detected at pixel location Top: 268, Left: 282, Bottom: 397, Right: 153\n",
      "A face is detected at pixel location Top: 268, Left: 827, Bottom: 397, Right: 698\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import face_recognition\n",
    "face_recognition.__version__\n",
    "\n",
    "given_image = face_recognition.load_image_file(\"E:\\\\TNU\\\\TNU Mini Project\\\\Tested Photos\\\\women-young-women-friendship-young-woman-friends-best-friend-ladies-confident-woman_t20_ro03El.jpg\")\n",
    "\n",
    "face_locations = face_recognition.face_locations(given_image)\n",
    "number_of_faces = len(face_locations)\n",
    "print(\"We found {} face(s) in this image.\".format(number_of_faces))\n",
    "pil_image = PIL.Image.fromarray(given_image)\n",
    "\n",
    "for face_location in face_locations:\n",
    "    top, left, bottom, right = face_location\n",
    "    print(\"A face is detected at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "    draw = PIL.ImageDraw.Draw(pil_image)\n",
    "    draw.rectangle([left, top, right, bottom], outline=\"green\", width=10)\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Live Webcam Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "\n",
    "cascPath = sys.argv[1]\n",
    "faceCascade = cv2.CascadeClassifier(\"E:\\\\TNU\\\\TNU Mini Project\\\\Harcascade File\\\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition using Train and Test (Both Files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True] [0.38107083]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    " \n",
    "train = face_recognition.load_image_file('C:\\\\Users\\\\visha\\\\OneDrive\\\\Pictures\\\\Camera Roll\\\\Siddharth\\\\Raj.jpg')\n",
    "train = cv2.cvtColor(train,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "test = face_recognition.load_image_file('C:\\\\Users\\\\visha\\\\OneDrive\\\\Pictures\\\\Camera Roll\\\\RAJ Zamal.jpg')\n",
    "test = cv2.cvtColor(test,cv2.COLOR_BGR2RGB)\n",
    " \n",
    "faceLoc = face_recognition.face_locations(train)[0]\n",
    "encodetrain = face_recognition.face_encodings(train)[0]\n",
    "cv2.rectangle(train,(faceLoc[3],faceLoc[0]),(faceLoc[1],faceLoc[2]),(255,0,255),2)\n",
    " \n",
    "faceLocTest = face_recognition.face_locations(test)[0]\n",
    "encodeTest = face_recognition.face_encodings(test)[0]\n",
    "cv2.rectangle(test,(faceLocTest[3],faceLocTest[0]),(faceLocTest[1],faceLocTest[2]),(255,0,255),2)\n",
    " \n",
    "results = face_recognition.compare_faces([encodetrain],encodeTest)\n",
    "faceDis = face_recognition.face_distance([encodetrain],encodeTest)\n",
    "print(results,faceDis)\n",
    "cv2.putText(test,f'{results} {round(faceDis[0],2)}',(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    " \n",
    "cv2.imshow('Raj Zamal',train)\n",
    "\n",
    "cv2.imshow('Raj Zamal',test)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Using Live Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Siddharth.jpg', 'Vishal.jpg']\n",
      "['Siddharth', 'Vishal']\n",
      "Encoding Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "from datetime import datetime\n",
    " \n",
    "path = 'Untitled Folder'\n",
    "images = []\n",
    "classNames = []\n",
    "myList = os.listdir(path)\n",
    "print(myList)\n",
    "for cl in myList:\n",
    "    curImg = cv2.imread(f'{path}/{cl}')\n",
    "    images.append(curImg)\n",
    "    classNames.append(os.path.splitext(cl)[0])\n",
    "print(classNames)\n",
    " \n",
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList\n",
    " \n",
    "encodeListKnown = findEncodings(images)\n",
    "print('Encoding Complete')\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgS = cv2.resize(img,(0,0),None,0.25,0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    facesCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodesCurFrame = face_recognition.face_encodings(imgS,facesCurFrame)\n",
    " \n",
    "    for encodeFace,faceLoc in zip(encodesCurFrame,facesCurFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown,encodeFace)\n",
    "        matchIndex = np.argmin(faceDis)\n",
    " \n",
    "        if matches[matchIndex]:\n",
    "            name = classNames[matchIndex].upper()\n",
    "            y1,x2,y2,x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1*4,x2*4,y2*4,x1*4\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
    "            cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "    cv2.imshow('Webcam',img)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Face Recognition Taking Attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Siddharth.jpg', 'Vishal.jpg']\n",
      "['Siddharth', 'Vishal']\n",
      "Encoding Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "from datetime import datetime\n",
    " \n",
    "path = 'Untitled Folder'\n",
    "images = []\n",
    "classNames = []\n",
    "myList = os.listdir(path)\n",
    "print(myList)\n",
    "for cl in myList:\n",
    "    curImg = cv2.imread(f'{path}/{cl}')\n",
    "    images.append(curImg)\n",
    "    classNames.append(os.path.splitext(cl)[0])\n",
    "print(classNames)\n",
    " \n",
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList\n",
    " \n",
    "def markAttendance(name):\n",
    "    with open('Attendance.csv','r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = []\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            dtString = now.strftime('%H:%M:%S')\n",
    "            f.writelines(f'\\n{name},{dtString}')\n",
    "\n",
    "\n",
    "encodeListKnown = findEncodings(images)\n",
    "print('Encoding Complete')\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgS = cv2.resize(img,(0,0),None,0.25,0.25)\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    facesCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodesCurFrame = face_recognition.face_encodings(imgS,facesCurFrame)\n",
    " \n",
    "    for encodeFace,faceLoc in zip(encodesCurFrame,facesCurFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown,encodeFace)\n",
    "        #print(faceDis)\n",
    "        matchIndex = np.argmin(faceDis)\n",
    " \n",
    "        if matches[matchIndex]:\n",
    "            name = classNames[matchIndex].upper()\n",
    "            #print(name)\n",
    "            y1,x2,y2,x1 = faceLoc\n",
    "            y1, x2, y2, x1 = y1*4,x2*4,y2*4,x1*4\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
    "            cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "            markAttendance(name)\n",
    "    cv2.imshow('Webcam',img)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from datetime import datetime,date\n",
    "import mysql.connector\n",
    "import tkinter\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "def details(name,ima):\n",
    "    op = mysql.connector.connect(host=\"localhost\",user='root',passwd='vishal@2000',database='Attendance')\n",
    "    p = op.cursor()\n",
    "    p.execute(\"SELECT * FROM details, attend where details.F_Name = Attend.Name;\")\n",
    "    a = p.fetchall()\n",
    "\n",
    "    for i in a:\n",
    "        if i[0] == name:\n",
    "            name = i[0]\n",
    "            dob = i[2]\n",
    "            hgt = i[3]\n",
    "            ag = i[4]\n",
    "            Rol = i[5]\n",
    "            b_g = i[6]\n",
    "\n",
    "            cv2.putText(ima,f'Name={name}',(25,25),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.putText(ima,f'D-O-B={dob}',(25,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.putText(ima,f'Height={hgt}',(25,75),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.putText(ima,f'Age={ag}',(25,100),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.putText(ima,f'Roll={Rol}',(25,125),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.putText(ima,f'Blood_Gp={b_g}',(25,150),cv2.FONT_HERSHEY_COMPLEX,1,(2,255,0),2)\n",
    "\n",
    "def attenddbs(name):\n",
    "    op = mysql.connector.connect(host=\"localhost\",user='root',passwd='vishal@2000',database='Attendance')\n",
    "    p = op.cursor()\n",
    "    p.execute(\"SELECT Name FROM Attend;\")\n",
    "    a = p.fetchall()\n",
    "    out = [item for t in a for item in t]\n",
    "    if name not in out:\n",
    "        lst = []\n",
    "        now = datetime.now()\n",
    "        today = date.today()\n",
    "        dtString = now.strftime('%H:%M:%S')\n",
    "        d = today.strftime(\"%d-%b-%Y\")\n",
    "        lst.append(name)\n",
    "        lst.append(d)\n",
    "        lst.append(dtString)\n",
    "        t = tuple(lst)\n",
    "        p.execute(\"INSERT INTO Attend(Name,Date,Time) VALUES(%s,%s,%s);\",t)\n",
    "        op.commit()\n",
    "\n",
    "\n",
    "\n",
    "def registration():\n",
    "    w = tkinter.Toplevel()\n",
    "    w.title(\"Registration\")\n",
    "    w.geometry('680x420')\n",
    "\n",
    "    def f():\n",
    "        l = mysql.connector.connect(host='localhost',user='root',passwd='vishal@2000',database='Attendance')\n",
    "        u = l.cursor()\n",
    "        n = f_name.get()\n",
    "        m = l_name.get()\n",
    "        r = Rol.get()\n",
    "        d = dofb.get()\n",
    "        ag = age.get()\n",
    "        bg = b_group.get()\n",
    "        h = hei.get()\n",
    "\n",
    "        u.execute('insert into details(F_Name,L_Name,dob,height,age,roll_no,blood_group) values(%s,%s,%s,%s,%s,%s,%s);',(n,m,d,h,ag,r,bg))\n",
    "        l.commit()\n",
    "\n",
    "        f_name.set(\"\")\n",
    "        l_name.set(\"\")\n",
    "        Rol.set(\"\")\n",
    "        dofb.set(\"\")\n",
    "        age.set(0)\n",
    "        b_group.set(\"\")\n",
    "        hei.set(0.0)\n",
    "\n",
    "    f_name = tkinter.StringVar()\n",
    "    l_name = tkinter.StringVar()\n",
    "    Rol = tkinter.StringVar()\n",
    "    dofb = tkinter.StringVar()\n",
    "    age = tkinter.IntVar()\n",
    "    b_group = tkinter.StringVar()\n",
    "    hei = tkinter.DoubleVar()\n",
    "\n",
    "\n",
    "    f_nam = tkinter.Label(w,text='First Name',bg='white').place(x=20,y=20)\n",
    "    e = tkinter.Entry(w,textvariable=f_name).place(x=20,y=40,width=200)\n",
    "    l_nam = tkinter.Label(w,text='Last Name',bg='white').place(x=240,y=20)\n",
    "    e1 = tkinter.Entry(w,textvariable=l_name).place(x=240,y=40,width=200)\n",
    "    ag = tkinter.Label(w,text='Age',bg='white').place(x=20,y=60)\n",
    "    a = tkinter.Entry(w,textvariable=age).place(x=20,y=80,width=200)\n",
    "    add = tkinter.Label(w,text='Date-of-Birth',bg='white').place(x=240,y=60)\n",
    "    ad = tkinter.Entry(w,textvariable=dofb).place(x=240,y=80,width=200)\n",
    "    Roll = tkinter.Label(w,text='Roll',bg='white').place(x=20,y=100)\n",
    "    r = tkinter.Entry(w,textvariable=Rol).place(x=20,y=120,width=200)\n",
    "    B_g = tkinter.Label(w,text=\"Blood Group\").place(x=240,y=100)\n",
    "    b_g = tkinter.Entry(w,textvariable=b_group,bg='white').place(x=240,y=120)\n",
    "    height = tkinter.Label(w,text=\"height\").place(x=20,y=140)\n",
    "    h = tkinter.Entry(w,textvariable=hei,bg=\"white\").place(x=20,y=160)\n",
    "    tkinter.Label(w,text='Register Here',bg='Blue').place(x=300,y=0)\n",
    "    b = tkinter.Button(w,text=\"Submit\",command=f).pack(side='bottom')\n",
    "\n",
    "    w.mainloop()\n",
    "\n",
    "def main_start():\n",
    "    path = \"C:\\\\Users\\\\visha\\\\OneDrive\\\\Pictures\\\\New folder\"\n",
    "    images=[]\n",
    "    names=[]\n",
    "\n",
    "    mylist = os.listdir(path)\n",
    "\n",
    "    for c in mylist:\n",
    "        c_img = face_recognition.load_image_file(f'{path}//{c}')\n",
    "        images.append(c_img)\n",
    "        names.append(os.path.splitext(c)[0])\n",
    "\n",
    "    enc = []\n",
    "    for im in images:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "        i_e = face_recognition.face_encodings(im)[0]\n",
    "        enc.append(i_e)\n",
    "\n",
    "    print(\"Encoding Finished\")\n",
    "\n",
    "    c = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        s, ima = c.read()\n",
    "        imas = cv2.resize(ima,(0,0),None,0.25,0.25)\n",
    "        imas = cv2.cvtColor(imas,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        imasloc = face_recognition.face_locations(imas)\n",
    "        imas_e = face_recognition.face_encodings(imas,imasloc)\n",
    "\n",
    "        for eface,floc in zip(imas_e,imasloc):\n",
    "            matches = face_recognition.compare_faces(enc,eface)\n",
    "            f_dist = face_recognition.face_distance(enc,eface)\n",
    "\n",
    "            mat_in = np.argmin(f_dist)\n",
    "\n",
    "            if matches[mat_in]:\n",
    "                name = names[mat_in]\n",
    "                name = name.split()[0].upper()\n",
    "\n",
    "                t,r,b,l = floc\n",
    "                t,r,b,l = t*4,r*4,b*4,l*4\n",
    "                cv2.rectangle(ima,(l,t),(r,b),(255,0,0),2)\n",
    "                cv2.rectangle(ima,(l,b-40),(r,b),(255,0,0),cv2.FILLED)\n",
    "                cv2.putText(ima,name,(l+6,b-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "\n",
    "\n",
    "                attenddbs(name)\n",
    "                details(name,ima)\n",
    "\n",
    "        cv2.imshow(\"Webcam\",ima)\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "\n",
    "    c.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "root = tkinter.Tk()\n",
    "root.title(\"Face Recognition\")\n",
    "\n",
    "img = ImageTk.PhotoImage(Image.open(\"D:\\\\Profile.jpg\"))\n",
    "panel = tkinter.Label(root, image = img)\n",
    "panel.pack(side = \"bottom\", fill = \"both\", expand = \"yes\")\n",
    "b = tkinter.Button(root,text=\"Start\",command=main_start)\n",
    "b.pack(side=\"left\")\n",
    "b2 = tkinter.Button(root,text=\"Register\",command=registration).pack(side='left')\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
